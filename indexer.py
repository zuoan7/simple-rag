from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.vectorstores import FAISS
import os.path
from dotenv import  load_dotenv

load_dotenv(".env")

# ========== 1. éªŒè¯ PDF æ–‡ä»¶è·¯å¾„ ==========
pdf_path = r'LLM.pdf'
if not os.path.exists(pdf_path):
    raise FileNotFoundError(f"âŒ PDF æ–‡ä»¶ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥è·¯å¾„ï¼š{pdf_path}")

# ========== 2. åŠ è½½å¹¶åˆ†å‰² PDF ==========
# åŠ è½½ PDFï¼ˆæ”¯æŒå›¾ç‰‡æ–‡å­—è§£æï¼Œéœ€ rapidocr-onnxruntime å·²å®‰è£…ï¼‰
pdf_loader = PyPDFLoader(pdf_path, extract_images=True)
# æ–‡æœ¬åˆ†å‰²ï¼ˆé€‚é…ä¸­æ–‡çš„åˆç†å‚æ•°ï¼‰
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,  # æ¯ä¸ªæ–‡æœ¬ç‰‡æ®µ 500 å­—
    chunk_overlap=50,  # ç‰‡æ®µé‡å  50 å­—ï¼Œä¿è¯è¯­ä¹‰è¿è´¯
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", "ã€"]  # ä¸­æ–‡åˆ†å‰²ç¬¦
)
chunks = pdf_loader.load_and_split(text_splitter=text_splitter)
print(f"ğŸ“„ æˆåŠŸè§£æ PDFï¼Œåˆ†å‰²ä¸º {len(chunks)} ä¸ªæ–‡æœ¬ç‰‡æ®µ")

# ========== 3. åŠ è½½åµŒå…¥æ¨¡å‹ ==========
# ä½¿ç”¨é€šä¹‰åƒé—®çš„åµŒå…¥æ¨¡å‹
embeddings = DashScopeEmbeddings(
    model="text-embedding-v1",
    dashscope_api_key=os.getenv("DASHSCOPE_API_KEY")
)

# ========== 4. ç”Ÿæˆå¹¶ä¿å­˜ FAISS å‘é‡åº“ ==========
vector_db = FAISS.from_documents(chunks, embeddings)
vector_db.save_local('LLM.faiss')

# ========== 5. è¾“å‡ºæˆåŠŸä¿¡æ¯ ==========
print(f"âœ… å‘é‡åº“ç”ŸæˆæˆåŠŸï¼")
print(f"ğŸ“ å‘é‡åº“ä¿å­˜è·¯å¾„ï¼š{os.path.abspath('LLM.faiss')}")
